# -*- coding: utf-8 -*-
import os
import time
import datetime as dt
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from dotenv import load_dotenv

# ë‚´ë¶€ ëª¨ë“ˆ (ì‹¤ë°ì´í„°ë§Œ ì‚¬ìš©)
from clients.searchad import NaverSearchAdClient
from clients.datalab import NaverDataLabClient

from core.recommend import apply_filters, annotate_intent
from core.scoring import rank_keywords
from core.trends import rising_from_datalab
from core.seasonality import seasonality_table, seasonal_index
from core.export_excel import export_keyword_report
from core.longtail import suggest_longtails
from core.rank_split import naver_platform_ranks  # ë„¤ì´ë²„/í‹°ìŠ¤í† ë¦¬ ìˆœìœ„ ë¶„ë¦¬

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Naver Keyword Analyzer - ë¸”ë¡œê·¸ ì‹¤ì „", layout="wide")
st.title("ğŸš€ Naver Keyword Analyzer - ë¸”ë¡œê·¸ ì‹¤ì „ (ì‹¤ì‹œê°„/ì‹¤ë°ì´í„°)")

# ì™¸ë¶€ API í—¬í¼
import requests
from bs4 import BeautifulSoup

_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
)

def fetch_naver_suggestions(query: str, st_code: str = "100") -> list:
    """ë„¤ì´ë²„ ìë™ì™„ì„±(ì‹¤ì‹œê°„) ì œì•ˆì–´."""
    try:
        url = "https://ac.search.naver.com/nx/ac"
        params = {
            "q": query,
            "st": st_code,  # 100/111 ë“±
            "r_format": "json",
            "r_enc": "utf-8",
            "frm": "nv",
            "ans": "2",
            "r_lt": "1",
        }
        r = requests.get(url, params=params, timeout=6, headers={"User-Agent": _UA})
        r.raise_for_status()
        j = r.json()
        out = []
        items = (j.get("items") or [])
        if items:
            for entry in items[0]:
                if isinstance(entry, list) and entry:
                    s = str(entry[0]).strip()
                    if s:
                        out.append(s)
        return out
    except Exception:
        return []

def google_cse_search(api_key: str, cx: str, q: str, num: int = 10) -> list:
    """Google CSE ê²°ê³¼ (Top N)."""
    try:
        url = "https://www.googleapis.com/customsearch/v1"
        params = {"key": api_key, "cx": cx, "q": q, "num": min(max(num, 1), 10)}
        r = requests.get(url, params=params, timeout=8, headers={"User-Agent": _UA})
        r.raise_for_status()
        j = r.json()
        items = j.get("items") or []
        return [{"title": it.get("title"), "link": it.get("link"), "snippet": it.get("snippet")} for it in items]
    except Exception:
        return []

def kakao_blog_search(api_key: str, query: str, size: int = 10, page: int = 1, sort: str = "recency") -> list:
    """Kakao ë¸”ë¡œê·¸ ê²€ìƒ‰ (í‹°ìŠ¤í† ë¦¬ í¬í•¨)."""
    try:
        url = "https://dapi.kakao.com/v2/search/blog"
        params = {"query": query, "size": min(max(size, 1), 50), "page": max(page, 1), "sort": sort}
        headers = {"Authorization": f"KakaoAK {api_key}", "User-Agent": _UA}
        r = requests.get(url, params=params, headers=headers, timeout=8)
        r.raise_for_status()
        j = r.json()
        return j.get("documents") or []
    except Exception:
        return []

def fetch_url_html(url: str, timeout: int = 10) -> str:
    """ì„ì˜ URL HTML."""
    try:
        r = requests.get(url, timeout=timeout, headers={"User-Agent": _UA})
        r.raise_for_status()
        return r.text
    except Exception:
        return ""

def analyze_html_structure(html: str) -> Dict[str, int]:
    """ê°„ë‹¨ HTML êµ¬ì¡° ë©”íŠ¸ë¦­(ë‹¨ì–´ìˆ˜/H2/H3/IMG/TABLE)."""
    try:
        soup = BeautifulSoup(html or "", "lxml")
    except Exception:
        return {"words": 0, "h2": 0, "h3": 0, "img": 0, "table": 0}
    for tag in soup(["script", "style", "noscript"]):
        tag.decompose()
    text = (soup.get_text(separator=" ") or "").strip()
    words = len([w for w in text.split() if w])
    h2 = len(soup.find_all("h2"))
    h3 = len(soup.find_all("h3"))
    img = len(soup.find_all("img"))
    table = len(soup.find_all("table"))
    return {"words": words, "h2": h2, "h3": h3, "img": img, "table": table}

# í™˜ê²½/ìœ í‹¸
def ensure_env() -> Dict[str, str]:
    """secrets â†’ .env â†’ os.environ ìˆœì„œë¡œ ì½ê¸°."""
    load_dotenv()

    def getv(name: str) -> str:
        try:
            return st.secrets.get(name, "") or os.getenv(name, "")
        except Exception:
            return os.getenv(name, "")

    keys = {
        "NAVER_AD_API_KEY": getv("NAVER_AD_API_KEY"),
        "NAVER_AD_SECRET_KEY": getv("NAVER_AD_SECRET_KEY"),
        "NAVER_AD_CUSTOMER_ID": getv("NAVER_AD_CUSTOMER_ID"),
        "NAVER_OPENAPI_CLIENT_ID": getv("NAVER_OPENAPI_CLIENT_ID"),
        "NAVER_OPENAPI_CLIENT_SECRET": getv("NAVER_OPENAPI_CLIENT_SECRET"),
        "GOOGLE_API_KEY": getv("GOOGLE_API_KEY"),
        "GOOGLE_CSE_CX": getv("GOOGLE_CSE_CX"),
        "KAKAO_REST_API_KEY": getv("KAKAO_REST_API_KEY"),
    }
    # í•„ìˆ˜: ë„¤ì´ë²„ 5ê°œë§Œ
    required = [
        "NAVER_AD_API_KEY",
        "NAVER_AD_SECRET_KEY",
        "NAVER_AD_CUSTOMER_ID",
        "NAVER_OPENAPI_CLIENT_ID",
        "NAVER_OPENAPI_CLIENT_SECRET",
    ]
    missing = [k for k in required if not keys.get(k)]
    if missing:
        st.error("API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: " + ", ".join(missing) + " â€” Secrets ë˜ëŠ” .envì— ì¶”ê°€í•˜ì„¸ìš”.")
        return {}
    return keys

def _to_int(x):
    try:
        s = str(x)
        if "<" in s:
            return 0
        return int(float(s.replace(",", "")))
    except Exception:
        return 0

def fmt_won(x: int) -> str:
    return f"{int(x):,}ì›"

def fmt_int(x: int) -> str:
    return f"{int(x):,}"

def call_with_backoff(fn, *args, tries=3, base_sleep=1.0, **kwargs):
    """ê°„ë‹¨ ì¬ì‹œë„ ë°±ì˜¤í”„."""
    for i in range(tries):
        try:
            return fn(*args, **kwargs)
        except Exception:
            if i == tries - 1:
                raise
            time.sleep(base_sleep * (2 ** i))

# ì´ˆë³´ì ê°€ì´ë“œ ë³´ì¡°
def beginner_article_type(intent: str) -> str:
    if intent in ("ê±°ë˜", "ìƒì—…"):
        return "ë¦¬ë·°/ë¹„êµ/êµ¬ë§¤ê°€ì´ë“œ"
    if intent == "ë‚´ë¹„ê²Œì´ì…˜":
        return "ë™ì„ /ì½”ìŠ¤/ì£¼ì°¨ ì•ˆë‚´"
    return "ì¢…í•© ê°€ì´ë“œ/ì²´í¬ë¦¬ìŠ¤íŠ¸"

def basic_ad_positions(platform: str) -> str:
    if platform.lower().startswith("tistory"):
        return "ìƒë‹¨ ì¸í”¼ë“œ 1 Â· ì¤‘ë‹¨ ì¸í”¼ë“œ 1 Â· í•˜ë‹¨ ë°°ë„ˆ 1"
    return "ìƒë‹¨ ì´ë¯¸ì§€ í•˜ë‹¨ 1 Â· ì¤‘ê°„ ë¬¸ë‹¨ ì‚¬ì´ 1 Â· ê²°ë¡  ì§ì „ 1"

def make_sponsor_pitch(brand: str, keyword: str, platform: str) -> str:
    brand = (brand or "íŒŒíŠ¸ë„ˆì‚¬").strip()
    platform = (platform or "ë¸”ë¡œê·¸").strip()
    return (
        f"ì•ˆë…•í•˜ì„¸ìš”, {brand} ë‹´ë‹¹ìë‹˜.\n\n"
        f"'{keyword}' ì£¼ì œë¡œ {platform}ë¥¼ ìš´ì˜í•˜ë©° ë…ìì—ê²Œ ì‹¤ì „ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n"
        f"ì´ë²ˆ ì£¼ì œì™€ {brand}ì˜ ì œí’ˆ/ì„œë¹„ìŠ¤ê°€ ì˜ ë§ì•„ ì²´í—˜ ë¦¬ë·°/ê°€ì´ë“œ í˜‘ì—…ì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤.\n\n"
        "ì œê³µ ê°€ëŠ¥: ì´¬ì˜ ì´ë¯¸ì§€Â·ì²´í¬ë¦¬ìŠ¤íŠ¸ PDFÂ·ê°€ê²©/ì˜µì…˜ ë¹„êµí‘œÂ·CTA ë°°ì¹˜(ìƒ/ì¤‘/í•˜)\n"
        "ë…¸ì¶œ: ìƒë‹¨ ìš”ì•½Â·ì¤‘ë‹¨ ë¹„êµí‘œÂ·ê²°ë¡  CTA, ë‚´ë¶€/ì™¸ë¶€ ë§í¬ ì—°ê³„\n"
        "ì¼ì •: ì´ˆì•ˆ 3ì¼, í”¼ë“œë°± ë°˜ì˜ í¬í•¨ 7ì¼ ë‚´ ê²Œì‹œ\n\n"
        "ê²€í†  ë¶€íƒë“œë¦½ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤."
    )

def unique_title_meta_for_row(kw: str, intent: str, vol_pc: int, vol_mo: int, rank: int) -> Dict[str, str]:
    """í‚¤ì›Œë“œë³„ ì¤‘ë³µ ì—†ëŠ” ì œëª©/ë©”íƒ€ ì´ˆì•ˆ."""
    base = kw.strip()
    total = (vol_pc or 0) + (vol_mo or 0)
    year = dt.date.today().year
    if intent in ("ê±°ë˜", "ìƒì—…"):
        patterns = [
            f"{base} {year} ìµœì €ê°€ ê°€ì´ë“œ | ê°€ê²©Â·ì˜µì…˜ ë¹„êµí‘œ",
            f"{base} ì‹¤íŒ¨ ì—†ëŠ” êµ¬ë§¤ ì²´í¬ë¦¬ìŠ¤íŠ¸ 12ê°€ì§€",
            f"{base} TOP7 ëª¨ë¸ ë¹„êµ | ì˜ˆì‚°Â·ìš©ë„ë³„ ì¶”ì²œ",
            f"{base} ì‹¤ì‚¬ìš© í›„ê¸° í•µì‹¬ë§Œ | ì¥ë‹¨ì  ìš”ì•½",
            f"{base} ì‹ ìƒ vs ê°€ì„±ë¹„ | ëˆ„êµ¬ì—ê²Œ ë¬´ì—‡ì´ ì¢‹ë‚˜",
        ]
        metas = [
            f"{base} ì‚¬ê¸° ì „ ê¼­ í™•ì¸í•  ì²´í¬ë¦¬ìŠ¤íŠ¸ì™€ ê°€ê²©/ì˜µì…˜ ë¹„êµí‘œë¥¼ ë‹´ì•˜ìŠµë‹ˆë‹¤. ì¿ í°/í™˜ë¶ˆ íŒ í¬í•¨.",
            f"{base} êµ¬ë§¤ ì „ ê¶ê¸ˆí•œ ê²ƒë§Œ ëª¨ì•„ ê°„ë‹¨íˆ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ì‚¬ìš© ê¸°ì¤€ ì¥ë‹¨ì ê³¼ A/S ìš”ë ¹ê¹Œì§€.",
        ]
    elif intent == "ë‚´ë¹„ê²Œì´ì…˜":
        patterns = [
            f"{base} ê°€ëŠ” ë²•Â·ì£¼ì°¨Â·ë™ì„  10ë¶„ì»· | ì²˜ìŒ ê°€ëŠ” ì‚¬ëŒìš©",
            f"{base} ë‹¹ì¼ ì½”ìŠ¤ ì¶”ì²œ | ì‹œê°„ëŒ€ë³„ ë™ì„ í‘œ",
            f"{base} êµí†µ/ì£¼ì°¨ í˜„ì‹¤ì •ë¦¬ | í”¼í¬ì‹œê°„ íšŒí”¼ íŒ",
        ]
        metas = [
            f"{base} ì²˜ìŒ ê°€ë„ í—¤ë§¤ì§€ ì•Šê²Œ ë™ì„ /ì£¼ì°¨/ì†Œìš”ì‹œê°„ì„ í•œ ë²ˆì— ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ì§€ë„Â·ë¹„ìš©Â·ì£¼ì˜ì‚¬í•­ í¬í•¨.",
        ]
    else:
        patterns = [
            f"{base} ì™„ë²½ ê°€ì´ë“œ | í•µì‹¬ë§Œ ë¹ ë¥´ê²Œ ì •ë¦¬",
            f"{base} ì…ë¬¸ì„œ | ê¼­ ì•Œì•„ì•¼ í•  ê°œë…Â·ì‹¤ìˆ˜Â·ê¿€íŒ",
            f"{base} ì „ë¬¸ê°€ê°€ ë¨¼ì € ë³´ëŠ” ì²´í¬í¬ì¸íŠ¸ 15ê°€ì§€",
            f"{base} Q&A 20ë¬¸20ë‹µ | ëª¨ë¥´ë©´ ì†í•´ë³´ëŠ” í¬ì¸íŠ¸",
        ]
        metas = [
            f"{base}ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ í•œ ë²ˆì—. í•µì‹¬ ê°œë…, ì¼€ì´ìŠ¤, ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜ë¥¼ ê°„ë‹¨íˆ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.",
        ]
    if total >= 20000:
        patterns = [p.replace("ê°€ì´ë“œ", "ì´ˆê²©ì°¨ ê°€ì´ë“œ").replace("ì…ë¬¸ì„œ", "ì‹¤ì „ ì…ë¬¸ì„œ") for p in patterns]
    title = patterns[rank % len(patterns)]
    meta = metas[rank % len(metas)]
    if len(title) > 38:
        title = title[:36] + "â€¦"
    if len(meta) > 110:
        meta = meta[:108] + "â€¦"
    return {"title": title, "meta": meta}

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ì„¤ì •")
    seed = st.text_input("ì”¨ì•— í‚¤ì›Œë“œ", value=st.session_state.get("_seed", "ë§ˆì¹´ì˜¤ ì—¬í–‰"))
    months = st.slider("DataLab ê¸°ê°„(ê°œì›”)", 3, 24, 12)
    min_volume = st.number_input("ìµœì†Œ ê²€ìƒ‰ëŸ‰(PC+MO)", 0, 1_000_000, 50, 10)
    max_len = st.number_input("í‚¤ì›Œë“œ ìµœëŒ€ ê¸€ììˆ˜", 5, 40, 25, 1)
    ban_tokens = st.text_input("ê¸ˆì¹™ì–´(ì‰¼í‘œ)", value="ë¬´ë£Œ,ë‹¤ìš´ë¡œë“œ,í† ë ŒíŠ¸,ì„±ì¸")
    device = st.selectbox("ë””ë°”ì´ìŠ¤", ["", "pc", "mo"], index=0)
    topn = st.slider("í‘œì‹œ ê°œìˆ˜(Top N)", 10, 500, 150, 10)

    st.markdown("---")
    beginner_mode = st.checkbox("ì´ˆë³´ì ëª¨ë“œ (ê°€ì´ë“œ í‘œì‹œ)", value=st.session_state.get("_beginner", True))

    st.markdown("---")
    cpc_assume = st.number_input("(ì„ íƒ) CPC ê°€ì •(ì›) â€” í‘œì‹œìš©", 10, 5000, 80, 10)
    rpm_bonus = st.number_input("(ì„ íƒ) ë³´ë„ˆìŠ¤ ìˆ˜ìµ(ì›/ì›”) â€” í‘œì‹œìš©", 0, 10_000_000, 0, 1000)

    st.session_state.update({
        "_seed": seed, "_months": months, "_min_volume": min_volume,
        "_max_len": max_len, "_ban_tokens": ban_tokens,
        "_device": device, "_topn": topn, "_cpc": cpc_assume,
        "_rpm": rpm_bonus,
        "_beginner": beginner_mode
    })
    run = st.button("ë¶„ì„ ì‹¤í–‰ / ê°±ì‹ ", key="btn_run")

# ì‹¤í–‰
if run or st.session_state.get("_ran_once", False):
    st.session_state["_ran_once"] = True
    keys = st.session_state.get("_naver_keys") or ensure_env()
    if not keys:
        st.stop()
    st.session_state["_naver_keys"] = keys

    ad = NaverSearchAdClient(keys["NAVER_AD_API_KEY"], keys["NAVER_AD_SECRET_KEY"], keys["NAVER_AD_CUSTOMER_ID"])
    dl = NaverDataLabClient(keys["NAVER_OPENAPI_CLIENT_ID"], keys["NAVER_OPENAPI_CLIENT_SECRET"])

    # 1) SearchAd ì—°ê´€í‚¤ì›Œë“œ â†’ í•„í„°/ë­í¬/ì˜ë„
    with st.spinner("ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³ : ì—°ê´€ í‚¤ì›Œë“œ ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì¤‘â€¦"):
        rel = call_with_backoff(ad.related_keywords, seed, show_detail=True, max_rows=1000)
        filtered = apply_filters(rel, min_volume, max_len, [t.strip() for t in ban_tokens.split(",") if t.strip()])
        ranked = rank_keywords(filtered, mobile_weight=1.2)
        annotate_intent(ranked)
        if not ranked:
            st.warning("ì¡°ê±´ì— ë§ëŠ” í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì™„í™”í•´ ë³´ì„¸ìš”.")
            st.stop()
        df = pd.DataFrame(ranked[:topn])

    # 2) DataLab ì›”ê°„ íŠ¸ë Œë“œ
    with st.spinner("ë„¤ì´ë²„ ë°ì´í„°ë©: íŠ¸ë Œë“œ(ì›” ë‹¨ìœ„) ì¡°íšŒ ì¤‘â€¦"):
        end = dt.date.today()
        start = end - dt.timedelta(days=30 * months)
        kw_list = df["relKeyword"].head(5).tolist() or [seed]
        try:
            res = call_with_backoff(
                dl.trend, kw_list, start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d"),
                time_unit="month", device=device
            )
        except Exception as e:
            res = {}
            st.info(f"DataLab í˜¸ì¶œ ì‹¤íŒ¨(ê³„ì† ì§„í–‰): {e}")

    rising = rising_from_datalab(res, topn=20) if res else pd.DataFrame()

    # 3) ìˆ˜ìµ(í‘œì‹œìš©) ê³„ì‚°
    money_df = df.copy()
    for c in ["monthlyAvePcClkCnt", "monthlyAveMobileClkCnt"]:
        if c not in money_df.columns:
            money_df[c] = 0
        money_df[c] = money_df[c].apply(_to_int)
    money_df["ì›”ê°„_í´ë¦­_í•©ê³„"] = money_df["monthlyAvePcClkCnt"] + money_df["monthlyAveMobileClkCnt"]
    money_df["ì˜ˆìƒ_ë§¤ì¶œ(ì›)"] = money_df["ì›”ê°„_í´ë¦­_í•©ê³„"] * int(cpc_assume) + int(rpm_bonus)
    total_expected = int(money_df.get("ì˜ˆìƒ_ë§¤ì¶œ(ì›)", pd.Series(dtype=int)).sum()) if not money_df.empty else 0

    # íƒ­ êµ¬ì„±
    tabs = st.tabs([
        "ì‹œì‘í•˜ê¸°",
        "í”Œë«í¼ë³„ ìˆœìœ„",
        "ì œëª©/ë©”íƒ€ ì¶”ì²œ",
        "SERP í…œí”Œë¦¿",
        "ì‹œì¦Œì„±",
        "ë¡±í…Œì¼ ì¶”ì²œ",
        "êµ¬ê¸€ ìˆœìœ„",
        "ì¸ê¸°/ì¸êµ¬í†µê³„",
    ])

    # A) ì‹œì‘í•˜ê¸°
    with tabs[0]:
        if st.session_state.get("_beginner"):
            st.markdown("### ğŸ‘¶ ì´ˆë³´ì ê°€ì´ë“œ")
            st.info("1) ì”¨ì•— ì…ë ¥ â†’ 2) [ë¶„ì„ ì‹¤í–‰ / ê°±ì‹ ] â†’ 3) [ë¡±í…Œì¼ ì¶”ì²œ]/[ì œëª©/ë©”íƒ€ ì¶”ì²œ] ì°¸ê³  â†’ 4) ë°œí–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸ â†’ 5) [í”Œë«í¼ë³„/êµ¬ê¸€ ìˆœìœ„] í™•ì¸")
            with st.expander("ë°œí–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸", expanded=True):
                c1, c2 = st.columns(2)
                with c1:
                    st.checkbox("í‚¤ì›Œë“œ 1ê°œ = ê¸€ 1ê°œ", True, key="ck_kw1")
                    st.checkbox("ì„œë¡  3~5ë¬¸ì¥, í•µì‹¬ ìš”ì•½ ìƒë‹¨", True, key="ck_intro")
                    st.checkbox("ì´ë¯¸ì§€ 3~5ì¥(ALT í¬í•¨)", False, key="ck_img")
                with c2:
                    st.checkbox("ì¤‘ê°„ H2/H3ì— í‚¤ì›Œë“œ/ë³€í˜•", True, key="ck_h2")
                    st.checkbox("ìƒ/ì¤‘/í•˜ CTA ë°°ì¹˜", True, key="ck_cta")
                    st.checkbox("ë‚´ë¶€ë§í¬ 2~3ê°œ", False, key="ck_internal")
            st.markdown("---")

        st.subheader("ğŸ“Œ ê°œìš”(í‘œì‹œìš©)")
        col1, col2 = st.columns(2)
        col1.metric("í‘œì‹œ í‚¤ì›Œë“œ ìˆ˜", fmt_int(len(money_df)))
        col2.metric("ì›” ì˜ˆìƒ ë§¤ì¶œ í•©ê³„(í‘œì‹œìš©)", fmt_won(total_expected))

        show = money_df.sort_values("ì˜ˆìƒ_ë§¤ì¶œ(ì›)", ascending=False).head(30)[[
            "relKeyword", "intent", "monthlyPcQcCnt", "monthlyMobileQcCnt",
            "monthlyAvePcClkCnt", "monthlyAveMobileClkCnt", "ì˜ˆìƒ_ë§¤ì¶œ(ì›)"
        ]].rename(columns={
            "relKeyword": "í‚¤ì›Œë“œ", "intent": "ì˜ë„", "monthlyPcQcCnt": "PCê²€ìƒ‰ëŸ‰", "monthlyMobileQcCnt": "MOê²€ìƒ‰ëŸ‰",
            "monthlyAvePcClkCnt": "PCí´ë¦­", "monthlyAveMobileClkCnt": "MOí´ë¦­"
        })
        for c in ["PCê²€ìƒ‰ëŸ‰", "MOê²€ìƒ‰ëŸ‰", "PCí´ë¦­", "MOí´ë¦­"]:
            show[c] = show[c].apply(_to_int).apply(fmt_int)
        show["ì˜ˆìƒ_ë§¤ì¶œ(ì›)"] = show["ì˜ˆìƒ_ë§¤ì¶œ(ì›)"].apply(fmt_won)
        st.dataframe(show, use_container_width=True)

        st.markdown("#### âœï¸ ì‹¤ì œ ì‘ì„± ê°€ì´ë“œ(ìƒìœ„ 10)")
        plan_rows = []
        for _, r0 in money_df.sort_values("ì˜ˆìƒ_ë§¤ì¶œ(ì›)", ascending=False).head(10).iterrows():
            it = r0.get("intent", "ì •ë³´")
            plan_rows.append({
                "í‚¤ì›Œë“œ": r0["relKeyword"],
                "ì˜ë„": it,
                "ê¶Œì¥ ê¸€ ìœ í˜•": beginner_article_type(it),
                "í‹°ìŠ¤í† ë¦¬ ê´‘ê³ ": basic_ad_positions("Tistory"),
                "ë„¤ì´ë²„ ê´‘ê³ ": basic_ad_positions("Naver Blog"),
            })
        st.dataframe(pd.DataFrame(plan_rows), use_container_width=True)

        st.markdown("### ğŸ“ˆ DataLab ê¸‰ìƒìŠ¹(ì›”)")
        if isinstance(rising, pd.DataFrame) and not rising.empty:
            st.dataframe(rising, use_container_width=True)
        else:
            st.info("í‘œì‹œí•  ê¸‰ìƒìŠ¹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        if st.button("â¬‡ï¸ ì—‘ì…€ ë‚´ë³´ë‚´ê¸°(ìˆ˜ìµ í¬í•¨)", key="btn_export_overview"):
            try:
                xlsx = export_keyword_report(seed, money_df.to_dict("records"), rising)
                st.success(f"ì €ì¥ ì™„ë£Œ: {xlsx}")
            except Exception as e:
                st.error(f"ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")

        st.markdown("### ğŸ¤ í˜‘ì°¬ ì œì•ˆì„œ ë§Œë“¤ê¸°")
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            brand = st.text_input("ë¸Œëœë“œ/ì—…ì²´ëª…", value="ì˜ˆ) ì—¬í–‰ì‚¬ A")
        with c2:
            plat = st.selectbox("í”Œë«í¼", ["í‹°ìŠ¤í† ë¦¬", "ë„¤ì´ë²„ ë¸”ë¡œê·¸"])
        with c3:
            pick_kw = st.selectbox("ëŒ€ìƒ í‚¤ì›Œë“œ", options=money_df["relKeyword"].head(10).tolist() or [seed])
        pitch = make_sponsor_pitch(brand, pick_kw, plat)
        st.text_area("ì œì•ˆì„œ ì´ˆì•ˆ", value=pitch, height=180)
        st.download_button("â¬‡ï¸ í…ìŠ¤íŠ¸ ì €ì¥", data=pitch.encode("utf-8"), file_name="sponsor_pitch.txt", key="dl_pitch")

        st.markdown("### ğŸ—“ï¸ ì½˜í…ì¸  ìº˜ë¦°ë” (4ì£¼ ì œì•ˆ)")
        weeks = [
            ("1ì£¼ì°¨", "ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¤€ë¹„ë¬¼í˜• 2ê°œ + Q&A 1ê°œ"),
            ("2ì£¼ì°¨", "êµ¬ë§¤ê°€ì´ë“œ 1ê°œ + ë¦¬ë·° 1ê°œ + ë¹„êµ 1ê°œ"),
            ("3ì£¼ì°¨", "ëŒ€ì•ˆ/ë¹„êµ 2ê°œ + ë…¸í•˜ìš° 1ê°œ"),
            ("4ì£¼ì°¨", "ì¼€ì´ìŠ¤ ìŠ¤í„°ë”” 2ê°œ + ìš”ì•½ í—ˆë¸Œ 1ê°œ"),
        ]
        st.write("\n".join(f"- **{w}**: {plan}" for w, plan in weeks))

    # B) í”Œë«í¼ë³„ ìˆœìœ„ (ë„¤ì´ë²„ SERP)
    with tabs[1]:
        st.subheader("ğŸ” í”Œë«í¼ë³„ ìˆœìœ„ (ë„¤ì´ë²„ SERP)")
        kw_rank = st.text_input("ë¶„ì„ í‚¤ì›Œë“œ", value=seed, key="rank_kw")
        if st.button("ìˆœìœ„ ì¡°íšŒ", key="rank_check_main"):
            try:
                r = naver_platform_ranks(
                    kw_rank,
                    keys.get("NAVER_OPENAPI_CLIENT_ID", ""),
                    keys.get("NAVER_OPENAPI_CLIENT_SECRET", ""),
                    display=50
                )
                colA, colB = st.columns(2)
                nav_r = r["ranks"]["naver"]; tis_r = r["ranks"]["tistory"]
                colA.metric("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìµœì´ˆ ë…¸ì¶œ", f"{nav_r}ìœ„" if nav_r else "ë¯¸ë…¸ì¶œ")
                colB.metric("í‹°ìŠ¤í† ë¦¬ ìµœì´ˆ ë…¸ì¶œ", f"{tis_r}ìœ„" if tis_r else "ë¯¸ë…¸ì¶œ")

                st.markdown("**ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìƒìœ„ URL**")
                if r["naver_top"]:
                    st.write("\n".join(f"{x['rank']}ìœ„ Â· {x['url']}" for x in r["naver_top"]))
                else:
                    st.write("ê²°ê³¼ ì—†ìŒ")

                st.markdown("---")
                st.markdown("**í‹°ìŠ¤í† ë¦¬ ìƒìœ„ URL**")
                if r["tistory_top"]:
                    st.write("\n".join(f"{x['rank']}ìœ„ Â· {x['url']}" for x in r["tistory_top"]))
                else:
                    st.write("ê²°ê³¼ ì—†ìŒ")
            except Exception as e:
                st.error(f"ìˆœìœ„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

        st.markdown("---")
        st.subheader("ğŸŸ  í‹°ìŠ¤í† ë¦¬/ë¸”ë¡œê·¸ ê²€ìƒ‰ (Kakao Search)")
        kakao_key = st.text_input("Kakao REST API Key", value=keys.get("KAKAO_REST_API_KEY", ""), type="password")
        kw_kakao = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ(ì¹´ì¹´ì˜¤)", value=kw_rank)
        size_kakao = st.slider("ê°€ì ¸ì˜¬ ê°œìˆ˜", 1, 50, 10, 1)
        if st.button("ì¹´ì¹´ì˜¤ ë¸”ë¡œê·¸ ê²€ìƒ‰", key="btn_kakao_search"):
            if not kakao_key:
                st.warning("Kakao REST API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                docs = kakao_blog_search(kakao_key, kw_kakao, size=size_kakao, page=1, sort="recency")
                if not docs:
                    st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    only_tistory = st.checkbox("í‹°ìŠ¤í† ë¦¬ë§Œ ë³´ê¸°", value=True)
                    rows = []
                    for d in docs:
                        url = d.get("url") or d.get("blogurl")
                        if only_tistory and (not url or "tistory.com" not in url):
                            continue
                        rows.append({
                            "title": d.get("title"),
                            "url": url,
                            "blogname": d.get("blogname"),
                            "datetime": d.get("datetime"),
                            "contents": d.get("contents"),
                        })
                    if rows:
                        st.dataframe(pd.DataFrame(rows), use_container_width=True)
                    else:
                        st.info("í‹°ìŠ¤í† ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ ë³´ê¸°ë¡œ í™•ì¸í•´ë³´ì„¸ìš”.")

        st.markdown("#### ğŸ§© ìƒìœ„ ê²°ê³¼ êµ¬ì¡° ë¶„ì„(ê°„ë‹¨)")
        analyze_count = st.slider("ë¶„ì„í•  ìƒìœ„ ê²°ê³¼ ìˆ˜", 1, 20, 5, 1)
        if st.button("ìƒìœ„ ê²°ê³¼ êµ¬ì¡° ë¶„ì„", key="btn_kakao_analyze"):
            if not kakao_key:
                st.warning("Kakao REST API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                docs = kakao_blog_search(kakao_key, kw_kakao, size=analyze_count, page=1, sort="accuracy")
                if not docs:
                    st.info("ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    met_rows = []
                    for d in docs:
                        url = d.get("url") or d.get("blogurl")
                        html = fetch_url_html(url)
                        m = analyze_html_structure(html)
                        met_rows.append({
                            "title": d.get("title"),
                            "url": url,
                            "words": m["words"],
                            "h2": m["h2"],
                            "h3": m["h3"],
                            "img": m["img"],
                            "table": m["table"],
                        })
                    dfm = pd.DataFrame(met_rows)
                    st.dataframe(dfm, use_container_width=True)
                    if not dfm.empty:
                        st.markdown("**í‰ê· ê°’(ëŒ€ëµ)**")
                        avg = dfm[["words", "h2", "h3", "img", "table"]].mean(numeric_only=True).round(1)
                        st.write(avg.to_frame().T)
                    ideas = [f"- {d.get('title')}: {d.get('contents')[:80]}â€¦" for d in docs]
                    st.markdown("**ë¹ ë¥¸ ì•„ì´ë””ì–´**")
                    st.write("\n".join(ideas))

    # C) ì œëª©/ë©”íƒ€ ì¶”ì²œ
    with tabs[2]:
        st.subheader("ğŸ§² í‚¤ì›Œë“œë³„ ê³ ìœ  ì œëª©/ë©”íƒ€")
        rows = []
        for i, r in money_df.head(50).reset_index(drop=True).iterrows():
            kw = r["relKeyword"]; it = r.get("intent", "ì •ë³´")
            pc = _to_int(r.get("monthlyPcQcCnt", 0)); mo = _to_int(r.get("monthlyMobileQcCnt", 0))
            pair = unique_title_meta_for_row(kw, it, pc, mo, rank=i)
            rows.append({"í‚¤ì›Œë“œ": kw, "ì˜ë„": it, "ì œëª©": pair["title"], "ë©”íƒ€ë””ìŠ¤í¬ë¦½ì…˜": pair["meta"]})
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

    # D) SERP í…œí”Œë¦¿ (ì„ íƒ)
    with tabs[3]:
        st.subheader("ğŸ§  ìƒìœ„ êµ¬ì¡° ì´ˆì•ˆ (í”Œë«í¼ë³„)")
        st.caption("ê°„ë‹¨í•œ êµ¬ì¡° ì´ˆì•ˆ/ì•„ì´ë””ì–´ë§Œ ì œê³µí•©ë‹ˆë‹¤.")
        st.write("- ì„œë¡ : ìš”ì•½(í•µì‹¬/ëª©ì°¨/ì£¼ì˜ì‚¬í•­)")
        st.write("- ë³¸ë¬¸(H2/H3): ë¹„êµí‘œÂ·ì²´í¬ë¦¬ìŠ¤íŠ¸Â·ì¼€ì´ìŠ¤Â·FAQ")
        st.write("- ê²°ë¡ : CTA(ìƒ/ì¤‘/í•˜), ë‚´ë¶€/ì™¸ë¶€ ë§í¬")

    # E) ì‹œì¦Œì„±
    with tabs[4]:
        st.subheader("ğŸ“… ì‹œì¦Œì„±/ì§€ìˆ˜")
        try:
            sea_df = seasonality_table(res) if res else pd.DataFrame()
            idx = seasonal_index(sea_df) if not sea_df.empty else pd.DataFrame()
            if not idx.empty:
                view = idx.copy()
                for c in view.columns:
                    view[c] = view[c].apply(lambda x: f"{float(x)*100:.0f}%" if pd.notnull(x) else "-")
                st.markdown("**ì›”ë³„ ìƒëŒ€ ì§€ìˆ˜(1.0 = ë³´í†µ)**")
                st.dataframe(view, use_container_width=True)
            else:
                st.info("í‘œì‹œí•  ì‹œì¦Œì„± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.warning(f"ì‹œì¦Œì„± ê³„ì‚° ì˜¤ë¥˜: {e}")

    # F) ë¡±í…Œì¼ ì¶”ì²œ
    with tabs[5]:
        st.subheader("ğŸŒ± ë¡±í…Œì¼ í‚¤ì›Œë“œ ì¶”ì²œ")
        method = st.radio("ë°©ì‹", ["SearchAd API ê¸°ë°˜", "ìë™ì™„ì„± ë©€í‹°-í”„ë¡¬í”„íŠ¸(ì‹¤ì‹œê°„)"], horizontal=True)

        def _export_df(df_out: pd.DataFrame, prefix: str) -> None:
            try:
                fname = f"{prefix}_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                df_out.to_excel(fname, index=False)
                st.success(f"ì €ì¥ ì™„ë£Œ: {fname}")
            except Exception as e:
                st.error(f"ì €ì¥ ì‹¤íŒ¨: {e}")

        if method == "SearchAd API ê¸°ë°˜":
            min_clicks = st.number_input("ìµœì†Œ ì›”í´ë¦­(í•„í„°)", 0, 100000, 20, 10)
            lt_df = suggest_longtails(df, min_clicks=min_clicks, max_items=300)
            if lt_df.empty:
                st.info("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ë¡±í…Œì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.")
            else:
                show_lt = lt_df.sort_values("ì›”í´ë¦­", ascending=False).reset_index(drop=True)
                st.dataframe(show_lt, use_container_width=True)
                if st.button("â¬‡ï¸ ë¡±í…Œì¼ ì¶”ì²œ ì—‘ì…€ ì €ì¥", key="btn_lt_export_api"):
                    _export_df(show_lt, "longtails_api")
        else:
            st.caption("â€¢ ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ë¡œ ë„¤ì´ë²„ ìë™ì™„ì„±ì„ ì¡°íšŒí•´, ì‹¤ì œ ì œì•ˆë§Œ ëª¨ì•„ ì¶”ì²œí•©ë‹ˆë‹¤ (ë”ë¯¸ ì—†ìŒ).")
            default_mods = "ì¶”ì²œ, ìˆœìœ„, í›„ê¸°, ê°€ê²©, í• ì¸, íŒ¨í‚¤ì§€, ì¼ì •, ì½”ìŠ¤, ê°€ì„±ë¹„, ìˆ™ì†Œ, ë§›ì§‘, ì•„ì´, ì»¤í”Œ, ë¶€ëª¨ë‹˜, 1ë°•2ì¼, 2ë°•3ì¼, ë‹¹ì¼, 9ì›”, 10ì›”, ì£¼ë§"
            mods_text = st.text_input("í”„ë¡¬í”„íŠ¸(ì‰¼í‘œ)", value=default_mods, help="ê° í•­ëª©ì€ ì”¨ì•— í‚¤ì›Œë“œì™€ í•¨ê»˜ ìë™ì™„ì„± ì¡°íšŒì— ì“°ì…ë‹ˆë‹¤.")
            min_hits = st.slider("ìµœì†Œ íˆíŠ¸ ìˆ˜(ì—¬ëŸ¬ í”„ë¡¬í”„íŠ¸ì— ì¤‘ë³µ ë“±ì¥)", 1, 5, 1, 1)
            max_items = st.slider("ìµœëŒ€ ì¶”ì²œ ê°œìˆ˜", 10, 500, 200, 10)

            def multi_prompt_autocomplete(seed_kw: str, modifiers: List[str], limit: int = 200) -> pd.DataFrame:
                prompts = [seed_kw]
                for m in modifiers:
                    m = m.strip()
                    if not m:
                        continue
                    prompts.append(f"{seed_kw} {m}")
                hits: Dict[str, int] = {}
                sample_prompt: Dict[str, str] = {}
                for p in prompts:
                    sugs = fetch_naver_suggestions(p, "100") + fetch_naver_suggestions(p, "111")
                    for s in sugs:
                        hits[s] = hits.get(s, 0) + 1
                        sample_prompt.setdefault(s, p)
                rows = [
                    {"keyword": k, "hits": v, "prompt": sample_prompt.get(k, ""), "source": "naver_autocomplete"}
                    for k, v in hits.items()
                ]
                out = pd.DataFrame(rows).sort_values(["hits", "keyword"], ascending=[False, True]).head(limit).reset_index(drop=True)
                return out

            if st.button("ì‹¤ì‹œê°„ ì¶”ì²œ ê°€ì ¸ì˜¤ê¸°", key="btn_mp_fetch"):
                modifiers = [t.strip() for t in mods_text.split(",") if t.strip()]
                ac_df = multi_prompt_autocomplete(seed, modifiers, limit=max_items)
                if ac_df.empty:
                    st.info("ì‹¤ì‹œê°„ ì œì•ˆì´ ì—†ìŠµë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ë°”ê¾¸ê±°ë‚˜ ë³´ì¡° ì”¨ì•—ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")
                else:
                    vol_map: Dict[str, Dict[str, Any]] = {}
                    try:
                        rel2 = ad.related_keywords(seed, show_detail=True, max_rows=2000)
                        for r2 in rel2 or []:
                            k2 = str(r2.get("relKeyword", "")).strip()
                            if k2:
                                vol_map[k2] = r2
                    except Exception:
                        pass
                    ac_df["monthlyPcQcCnt"] = ac_df["keyword"].map(lambda k: _to_int((vol_map.get(k) or {}).get("monthlyPcQcCnt")))
                    ac_df["monthlyMobileQcCnt"] = ac_df["keyword"].map(lambda k: _to_int((vol_map.get(k) or {}).get("monthlyMobileQcCnt")))
                    ac_df["totalVolume"] = ac_df["monthlyPcQcCnt"] + ac_df["monthlyMobileQcCnt"]
                    show_ac = ac_df[ac_df["hits"] >= min_hits].sort_values(["hits", "totalVolume"], ascending=[False, False])
                    st.dataframe(show_ac, use_container_width=True)
                    if st.button("â¬‡ï¸ ë¡±í…Œì¼ ì¶”ì²œ ì—‘ì…€ ì €ì¥", key="btn_lt_export_ac"):
                        _export_df(show_ac, "longtails_autocomplete")

    # G) êµ¬ê¸€ ìˆœìœ„ (CSE)
    with tabs[6]:
        st.subheader("ğŸ” êµ¬ê¸€ ê²€ìƒ‰ ìˆœìœ„ (CSE)")
        kw_g = st.text_input("êµ¬ê¸€ ìˆœìœ„ í‚¤ì›Œë“œ", value=seed, key="g_kw")
        num_g = st.slider("ê²€ì‚¬ ê°œìˆ˜(êµ¬ê¸€)", 1, 10, 10, 1)
        g_api = keys.get("GOOGLE_API_KEY", "")
        g_cx = keys.get("GOOGLE_CSE_CX", "")
        if not g_api or not g_cx:
            st.info("GOOGLE_API_KEY / GOOGLE_CSE_CXê°€ ì—†ìœ¼ë©´ CSEë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            if st.button("êµ¬ê¸€ ìˆœìœ„ ì¡°íšŒ", key="btn_google_rank"):
                try:
                    items = google_cse_search(g_api, g_cx, kw_g, num=num_g)
                    if not items:
                        st.info("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.markdown("**Top ê²°ê³¼**")
                        st.dataframe(pd.DataFrame(items), use_container_width=True)

                        col1, col2 = st.columns(2)

                except Exception as e:
                    st.error(f"êµ¬ê¸€ ìˆœìœ„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # H) ì¸ê¸°/ì¸êµ¬í†µê³„ (ì‹¤ì‹œê°„ ì œì•ˆ + DataLab)
    with tabs[7]:
        st.subheader("ğŸ”¥ ì¸ê¸°/ì¸êµ¬í†µê³„ (ì‹¤ì‹œê°„ + DataLab)")
        sug = list(dict.fromkeys(
            fetch_naver_suggestions(seed, "100") + fetch_naver_suggestions(seed, "111")
        ))[:10]
        if sug:
            st.markdown("**ë„¤ì´ë²„ ìë™ì™„ì„±(ì‹¤ì‹œê°„) ì œì•ˆ Top 10**")
            st.write("\n".join(f"- {s}" for s in sug))
        else:
            st.info("ì‹¤ì‹œê°„ ì œì•ˆì´ ì—†ìŠµë‹ˆë‹¤. ë³´ì¡° ì”¨ì•—ì„ ì¶”ê°€í•´ ë³´ì„¸ìš”.")

        try:
            end = dt.date.today()
            start = end - dt.timedelta(days=30)

            def _avg_ratio(gender: str) -> float:
                tr = dl.trend([seed], start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'), time_unit='date', gender=gender)
                rs = tr.get('results') or []
                if not rs or not rs[0].get('data'):
                    return 0.0
                vals = [x.get('ratio') or 0 for x in rs[0]['data']]
                return sum(vals)/len(vals) if vals else 0.0

            male = _avg_ratio('m')
            female = _avg_ratio('f')
            st.markdown("**ì„±ë³„ ë¹„ì¤‘(ìƒëŒ€ê°’)**")
            st.bar_chart(pd.DataFrame({"ratio": [male, female]}, index=["ë‚¨ì„±", "ì—¬ì„±"]))

            ages = ['10', '20', '30', '40', '50', '60']
            age_vals = []
            for a in ages:
                tr = dl.trend([seed], start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'), time_unit='date', ages=[a])
                rs = tr.get('results') or []
                if not rs or not rs[0].get('data'):
                    age_vals.append(0.0)
                else:
                    vals = [x.get('ratio') or 0 for x in rs[0]['data']]
                    age_vals.append(sum(vals)/len(vals) if vals else 0.0)
            st.markdown("**ì—°ë ¹ëŒ€ ë¹„ì¤‘(ìƒëŒ€ê°’)**")
            st.bar_chart(pd.DataFrame({"ratio": age_vals}, index=[f"{a}ëŒ€" for a in ages]))
        except Exception as e:
            st.info(f"ì¸êµ¬í†µê³„ ì¡°íšŒ ì°¸ê³ : {e}")

else:
    st.info("ì™¼ìª½ì—ì„œ ì˜µì…˜ì„ ì„¤ì •í•˜ê³  **ë¶„ì„ ì‹¤í–‰ / ê°±ì‹ **ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")




