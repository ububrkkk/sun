# -*- coding: utf-8 -*-
import os
import time
import datetime as dt
from typing import Dict, Any, List, Optional

import pandas as pd
import streamlit as st
from dotenv import load_dotenv

# ÎÇ¥Î∂Ä Î™®Îìà (Ïã§Îç∞Ïù¥ÌÑ∞Îßå ÏÇ¨Ïö©)
from clients.searchad import NaverSearchAdClient
from clients.datalab import NaverDataLabClient

from core.recommend import apply_filters, annotate_intent
from core.scoring import rank_keywords
from core.trends import rising_from_datalab
from core.seasonality import seasonality_table, seasonal_index
from core.export_excel import export_keyword_report
from core.longtail import suggest_longtails
from core.rank_split import naver_platform_ranks  # ÎÑ§Ïù¥Î≤Ñ/Ìã∞Ïä§ÌÜ†Î¶¨ ÏàúÏúÑ Î∂ÑÎ¶¨

# ÌéòÏù¥ÏßÄ ÏÑ§Ï†ï
st.set_page_config(page_title="Naver Keyword Analyzer - Î∏îÎ°úÍ∑∏ Ïã§Ï†Ñ", layout="wide")
st.title("üöÄ Naver Keyword Analyzer - Î∏îÎ°úÍ∑∏ Ïã§Ï†Ñ (Ïã§ÏãúÍ∞Ñ/Ïã§Îç∞Ïù¥ÌÑ∞)")

# Ïô∏Î∂Ä API Ìó¨Ìçº
import requests
from bs4 import BeautifulSoup

_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
)

def fetch_naver_suggestions(query: str, st_code: str = "100") -> list:
    """ÎÑ§Ïù¥Î≤Ñ ÏûêÎèôÏôÑÏÑ±(Ïã§ÏãúÍ∞Ñ) Ï†úÏïàÏñ¥."""
    try:
        url = "https://ac.search.naver.com/nx/ac"
        params = {
            "q": query,
            "st": st_code,  # 100/111 Îì±
            "r_format": "json",
            "r_enc": "utf-8",
            "frm": "nv",
            "ans": "2",
            "r_lt": "1",
        }
        r = requests.get(url, params=params, timeout=6, headers={"User-Agent": _UA})
        r.raise_for_status()
        j = r.json()
        out = []
        items = (j.get("items") or [])
        if items:
            for entry in items[0]:
                if isinstance(entry, list) and entry:
                    s = str(entry[0]).strip()
                    if s:
                        out.append(s)
        return out
    except Exception:
        return []

def google_cse_search(api_key: str, cx: str, q: str, num: int = 10) -> list:
    """Google CSE Í≤∞Í≥º (Top N)."""
    try:
        url = "https://www.googleapis.com/customsearch/v1"
        params = {"key": api_key, "cx": cx, "q": q, "num": min(max(num, 1), 10)}
        r = requests.get(url, params=params, timeout=8, headers={"User-Agent": _UA})
        r.raise_for_status()
        j = r.json()
        items = j.get("items") or []
        return [{"title": it.get("title"), "link": it.get("link"), "snippet": it.get("snippet")} for it in items]
    except Exception:
        return []

def kakao_blog_search(api_key: str, query: str, size: int = 10, page: int = 1, sort: str = "recency") -> list:
    """Kakao Î∏îÎ°úÍ∑∏ Í≤ÄÏÉâ (Ìã∞Ïä§ÌÜ†Î¶¨ Ìè¨Ìï®)."""
    try:
        url = "https://dapi.kakao.com/v2/search/blog"
        params = {"query": query, "size": min(max(size, 1), 50), "page": max(page, 1), "sort": sort}
        headers = {"Authorization": f"KakaoAK {api_key}", "User-Agent": _UA}
        r = requests.get(url, params=params, headers=headers, timeout=8)
        r.raise_for_status()
        j = r.json()
        return j.get("documents") or []
    except Exception:
        return []

def fetch_url_html(url: str, timeout: int = 10) -> str:
    """ÏûÑÏùò URL HTML."""
    try:
        r = requests.get(url, timeout=timeout, headers={"User-Agent": _UA})
        r.raise_for_status()
        return r.text
    except Exception:
        return ""

def analyze_html_structure(html: str) -> Dict[str, int]:
    """Í∞ÑÎã® HTML Íµ¨Ï°∞ Î©îÌä∏Î¶≠(Îã®Ïñ¥Ïàò/H2/H3/IMG/TABLE)."""
    try:
        soup = BeautifulSoup(html or "", "lxml")
    except Exception:
        return {"words": 0, "h2": 0, "h3": 0, "img": 0, "table": 0}
    for tag in soup(["script", "style", "noscript"]):
        tag.decompose()
    text = (soup.get_text(separator=" ") or "").strip()
    words = len([w for w in text.split() if w])
    h2 = len(soup.find_all("h2"))
    h3 = len(soup.find_all("h3"))
    img = len(soup.find_all("img"))
    table = len(soup.find_all("table"))
    return {"words": words, "h2": h2, "h3": h3, "img": img, "table": table}

# ÌôòÍ≤Ω/Ïú†Ìã∏
def ensure_env() -> Dict[str, str]:
    """secrets ‚Üí .env ‚Üí os.environ ÏàúÏÑúÎ°ú ÏùΩÍ∏∞."""
    load_dotenv()

    def getv(name: str) -> str:
        try:
            return st.secrets.get(name, "") or os.getenv(name, "")
        except Exception:
            return os.getenv(name, "")

    keys = {
        "NAVER_AD_API_KEY": getv("NAVER_AD_API_KEY"),
        "NAVER_AD_SECRET_KEY": getv("NAVER_AD_SECRET_KEY"),
        "NAVER_AD_CUSTOMER_ID": getv("NAVER_AD_CUSTOMER_ID"),
        "NAVER_OPENAPI_CLIENT_ID": getv("NAVER_OPENAPI_CLIENT_ID"),
        "NAVER_OPENAPI_CLIENT_SECRET": getv("NAVER_OPENAPI_CLIENT_SECRET"),
        "GOOGLE_API_KEY": getv("GOOGLE_API_KEY"),
        "GOOGLE_CSE_CX": getv("GOOGLE_CSE_CX"),
        "KAKAO_REST_API_KEY": getv("KAKAO_REST_API_KEY"),
    }
    # ÌïÑÏàò: ÎÑ§Ïù¥Î≤Ñ 5Í∞úÎßå
    required = [
        "NAVER_AD_API_KEY",
        "NAVER_AD_SECRET_KEY",
        "NAVER_AD_CUSTOMER_ID",
        "NAVER_OPENAPI_CLIENT_ID",
        "NAVER_OPENAPI_CLIENT_SECRET",
    ]
    missing = [k for k in required if not keys.get(k)]
    if missing:
        st.error("API ÌÇ§Í∞Ä ÏóÜÏäµÎãàÎã§: " + ", ".join(missing) + " ‚Äî Secrets ÎòêÎäî .envÏóê Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.")
        return {}
    return keys

def _to_int(x):
    try:
        s = str(x)
        if "<" in s:
            return 0
        return int(float(s.replace(",", "")))
    except Exception:
        return 0

def fmt_won(x: int) -> str:
    return f"{int(x):,}Ïõê"

def fmt_int(x: int) -> str:
    return f"{int(x):,}"

def call_with_backoff(fn, *args, tries=3, base_sleep=1.0, **kwargs):
    """Í∞ÑÎã® Ïû¨ÏãúÎèÑ Î∞±Ïò§ÌîÑ."""
    for i in range(tries):
        try:
            return fn(*args, **kwargs)
        except Exception:
            if i == tries - 1:
                raise
            time.sleep(base_sleep * (2 ** i))

# Ï¥àÎ≥¥Ïûê Í∞ÄÏù¥Îìú Î≥¥Ï°∞
def beginner_article_type(intent: str) -> str:
    if intent in ("Í±∞Îûò", "ÏÉÅÏóÖ"):
        return "Î¶¨Î∑∞/ÎπÑÍµê/Íµ¨Îß§Í∞ÄÏù¥Îìú"
    if intent == "ÎÇ¥ÎπÑÍ≤åÏù¥ÏÖò":
        return "ÎèôÏÑ†/ÏΩîÏä§/Ï£ºÏ∞® ÏïàÎÇ¥"
    return "Ï¢ÖÌï© Í∞ÄÏù¥Îìú/Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏"

def basic_ad_positions(platform: str) -> str:
    if platform.lower().startswith("tistory"):
        return "ÏÉÅÎã® Ïù∏ÌîºÎìú 1 ¬∑ Ï§ëÎã® Ïù∏ÌîºÎìú 1 ¬∑ ÌïòÎã® Î∞∞ÎÑà 1"
    return "ÏÉÅÎã® Ïù¥ÎØ∏ÏßÄ ÌïòÎã® 1 ¬∑ Ï§ëÍ∞Ñ Î¨∏Îã® ÏÇ¨Ïù¥ 1 ¬∑ Í≤∞Î°† ÏßÅÏ†Ñ 1"

def make_sponsor_pitch(brand: str, keyword: str, platform: str) -> str:
    brand = (brand or "ÌååÌä∏ÎÑàÏÇ¨").strip()
    platform = (platform or "Î∏îÎ°úÍ∑∏").strip()
    return (
        f"ÏïàÎÖïÌïòÏÑ∏Ïöî, {brand} Îã¥ÎãπÏûêÎãò.\n\n"
        f"'{keyword}' Ï£ºÏ†úÎ°ú {platform}Î•º Ïö¥ÏòÅÌïòÎ©∞ ÎèÖÏûêÏóêÍ≤å Ïã§Ï†Ñ Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï©ÎãàÎã§.\n"
        f"Ïù¥Î≤à Ï£ºÏ†úÏôÄ {brand}Ïùò Ï†úÌíà/ÏÑúÎπÑÏä§Í∞Ä Ïûò ÎßûÏïÑ Ï≤¥Ìóò Î¶¨Î∑∞/Í∞ÄÏù¥Îìú ÌòëÏóÖÏùÑ Ï†úÏïàÎìúÎ¶ΩÎãàÎã§.\n\n"
        "Ï†úÍ≥µ Í∞ÄÎä•: Ï¥¨ÏòÅ Ïù¥ÎØ∏ÏßÄ¬∑Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ PDF¬∑Í∞ÄÍ≤©/ÏòµÏÖò ÎπÑÍµêÌëú¬∑CTA Î∞∞Ïπò(ÏÉÅ/Ï§ë/Ìïò)\n"
        "ÎÖ∏Ï∂ú: ÏÉÅÎã® ÏöîÏïΩ¬∑Ï§ëÎã® ÎπÑÍµêÌëú¬∑Í≤∞Î°† CTA, ÎÇ¥Î∂Ä/Ïô∏Î∂Ä ÎßÅÌÅ¨ Ïó∞Í≥Ñ\n"
        "ÏùºÏ†ï: Ï¥àÏïà 3Ïùº, ÌîºÎìúÎ∞± Î∞òÏòÅ Ìè¨Ìï® 7Ïùº ÎÇ¥ Í≤åÏãú\n\n"
        "Í≤ÄÌÜ† Î∂ÄÌÉÅÎìúÎ¶ΩÎãàÎã§. Í∞êÏÇ¨Ìï©ÎãàÎã§."
    )

def unique_title_meta_for_row(kw: str, intent: str, vol_pc: int, vol_mo: int, rank: int) -> Dict[str, str]:
    """ÌÇ§ÏõåÎìúÎ≥Ñ Ï§ëÎ≥µ ÏóÜÎäî Ï†úÎ™©/Î©îÌÉÄ Ï¥àÏïà."""
    base = kw.strip()
    total = (vol_pc or 0) + (vol_mo or 0)
    year = dt.date.today().year
    if intent in ("Í±∞Îûò", "ÏÉÅÏóÖ"):
        patterns = [
            f"{base} {year} ÏµúÏ†ÄÍ∞Ä Í∞ÄÏù¥Îìú | Í∞ÄÍ≤©¬∑ÏòµÏÖò ÎπÑÍµêÌëú",
            f"{base} Ïã§Ìå® ÏóÜÎäî Íµ¨Îß§ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ 12Í∞ÄÏßÄ",
            f"{base} TOP7 Î™®Îç∏ ÎπÑÍµê | ÏòàÏÇ∞¬∑Ïö©ÎèÑÎ≥Ñ Ï∂îÏ≤ú",
            f"{base} Ïã§ÏÇ¨Ïö© ÌõÑÍ∏∞ ÌïµÏã¨Îßå | Ïû•Îã®Ï†ê ÏöîÏïΩ",
            f"{base} Ïã†ÏÉÅ vs Í∞ÄÏÑ±ÎπÑ | ÎàÑÍµ¨ÏóêÍ≤å Î¨¥ÏóáÏù¥ Ï¢ãÎÇò",
        ]
        metas = [
            f"{base} ÏÇ¨Í∏∞ Ï†Ñ Íº≠ ÌôïÏù∏Ìï† Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ÏôÄ Í∞ÄÍ≤©/ÏòµÏÖò ÎπÑÍµêÌëúÎ•º Îã¥ÏïòÏäµÎãàÎã§. Ïø†Ìè∞/ÌôòÎ∂à ÌåÅ Ìè¨Ìï®.",
            f"{base} Íµ¨Îß§ Ï†Ñ Í∂ÅÍ∏àÌïú Í≤ÉÎßå Î™®ÏïÑ Í∞ÑÎã®Ìûà Ï†ïÎ¶¨ÌñàÏäµÎãàÎã§. ÏÇ¨Ïö© Í∏∞Ï§Ä Ïû•Îã®Ï†êÍ≥º A/S ÏöîÎ†πÍπåÏßÄ.",
        ]
    elif intent == "ÎÇ¥ÎπÑÍ≤åÏù¥ÏÖò":
        patterns = [
            f"{base} Í∞ÄÎäî Î≤ï¬∑Ï£ºÏ∞®¬∑ÎèôÏÑ† 10Î∂ÑÏª∑ | Ï≤òÏùå Í∞ÄÎäî ÏÇ¨ÎûåÏö©",
            f"{base} ÎãπÏùº ÏΩîÏä§ Ï∂îÏ≤ú | ÏãúÍ∞ÑÎåÄÎ≥Ñ ÎèôÏÑ†Ìëú",
            f"{base} ÍµêÌÜµ/Ï£ºÏ∞® ÌòÑÏã§Ï†ïÎ¶¨ | ÌîºÌÅ¨ÏãúÍ∞Ñ ÌöåÌîº ÌåÅ",
        ]
        metas = [
            f"{base} Ï≤òÏùå Í∞ÄÎèÑ Ìó§Îß§ÏßÄ ÏïäÍ≤å ÎèôÏÑ†/Ï£ºÏ∞®/ÏÜåÏöîÏãúÍ∞ÑÏùÑ Ìïú Î≤àÏóê Ï†ïÎ¶¨ÌñàÏäµÎãàÎã§. ÏßÄÎèÑ¬∑ÎπÑÏö©¬∑Ï£ºÏùòÏÇ¨Ìï≠ Ìè¨Ìï®.",
        ]
    else:
        patterns = [
            f"{base} ÏôÑÎ≤Ω Í∞ÄÏù¥Îìú | ÌïµÏã¨Îßå Îπ†Î•¥Í≤å Ï†ïÎ¶¨",
            f"{base} ÏûÖÎ¨∏ÏÑú | Íº≠ ÏïåÏïÑÏïº Ìï† Í∞úÎÖê¬∑Ïã§Ïàò¬∑ÍøÄÌåÅ",
            f"{base} Ï†ÑÎ¨∏Í∞ÄÍ∞Ä Î®ºÏ†Ä Î≥¥Îäî Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ 15Í∞ÄÏßÄ",
            f"{base} Q&A 20Î¨∏20Îãµ | Î™®Î•¥Î©¥ ÏÜêÌï¥Î≥¥Îäî Ìè¨Ïù∏Ìä∏",
        ]
        metas = [
            f"{base}Î•º Ï≤òÏùåÎ∂ÄÌÑ∞ ÎÅùÍπåÏßÄ Ìïú Î≤àÏóê. ÌïµÏã¨ Í∞úÎÖê, ÏºÄÏù¥Ïä§, ÏûêÏ£º ÌïòÎäî Ïã§ÏàòÎ•º Í∞ÑÎã®Ìûà Ï†ïÎ¶¨ÌñàÏäµÎãàÎã§.",
        ]
    if total >= 20000:
        patterns = [p.replace("Í∞ÄÏù¥Îìú", "Ï¥àÍ≤©Ï∞® Í∞ÄÏù¥Îìú").replace("ÏûÖÎ¨∏ÏÑú", "Ïã§Ï†Ñ ÏûÖÎ¨∏ÏÑú") for p in patterns]
    title = patterns[rank % len(patterns)]
    meta = metas[rank % len(metas)]
    if len(title) > 38:
        title = title[:36] + "‚Ä¶"
    if len(meta) > 110:
        meta = meta[:108] + "‚Ä¶"
    return {"title": title, "meta": meta}

# ÏÇ¨Ïù¥ÎìúÎ∞î
with st.sidebar:
    st.header("ÏÑ§Ï†ï")
    seed = st.text_input("Ïî®Ïïó ÌÇ§ÏõåÎìú", value=st.session_state.get("_seed", "ÎßàÏπ¥Ïò§ Ïó¨Ìñâ"))
    months = st.slider("DataLab Í∏∞Í∞Ñ(Í∞úÏõî)", 3, 24, 12)
    min_volume = st.number_input("ÏµúÏÜå Í≤ÄÏÉâÎüâ(PC+MO)", 0, 1_000_000, 50, 10)
    max_len = st.number_input("ÌÇ§ÏõåÎìú ÏµúÎåÄ Í∏ÄÏûêÏàò", 5, 40, 25, 1)
    ban_tokens = st.text_input("Í∏àÏπôÏñ¥(ÏâºÌëú)", value="Î¨¥Î£å,Îã§Ïö¥Î°úÎìú,ÌÜ†Î†åÌä∏,ÏÑ±Ïù∏")
    device = st.selectbox("ÎîîÎ∞îÏù¥Ïä§", ["", "pc", "mo"], index=0)
    topn = st.slider("ÌëúÏãú Í∞úÏàò(Top N)", 10, 500, 150, 10)

    st.markdown("---")
    beginner_mode = st.checkbox("Ï¥àÎ≥¥Ïûê Î™®Îìú (Í∞ÄÏù¥Îìú ÌëúÏãú)", value=st.session_state.get("_beginner", True))

    st.markdown("---")
    cpc_assume = st.number_input("(ÏÑ†ÌÉù) CPC Í∞ÄÏ†ï(Ïõê) ‚Äî ÌëúÏãúÏö©", 10, 5000, 80, 10)
    rpm_bonus = st.number_input("(ÏÑ†ÌÉù) Î≥¥ÎÑàÏä§ ÏàòÏùµ(Ïõê/Ïõî) ‚Äî ÌëúÏãúÏö©", 0, 10_000_000, 0, 1000)

    st.session_state.update({
        "_seed": seed, "_months": months, "_min_volume": min_volume,
        "_max_len": max_len, "_ban_tokens": ban_tokens,
        "_device": device, "_topn": topn, "_cpc": cpc_assume,
        "_rpm": rpm_bonus,
        "_beginner": beginner_mode
    })
    run = st.button("Î∂ÑÏÑù Ïã§Ìñâ / Í∞±Ïã†", key="btn_run")

# Ïã§Ìñâ
if run or st.session_state.get("_ran_once", False):
    st.session_state["_ran_once"] = True
    keys = st.session_state.get("_naver_keys") or ensure_env()
    if not keys:
        st.stop()
    st.session_state["_naver_keys"] = keys

    ad = NaverSearchAdClient(keys["NAVER_AD_API_KEY"], keys["NAVER_AD_SECRET_KEY"], keys["NAVER_AD_CUSTOMER_ID"])
    dl = NaverDataLabClient(keys["NAVER_OPENAPI_CLIENT_ID"], keys["NAVER_OPENAPI_CLIENT_SECRET"])

    # 1) SearchAd Ïó∞Í¥ÄÌÇ§ÏõåÎìú ‚Üí ÌïÑÌÑ∞/Îû≠ÌÅ¨/ÏùòÎèÑ
    with st.spinner("ÎÑ§Ïù¥Î≤Ñ Í≤ÄÏÉâÍ¥ëÍ≥†: Ïó∞Í¥Ä ÌÇ§ÏõåÎìú Ïã§ÏãúÍ∞Ñ ÏàòÏßë Ï§ë‚Ä¶"):
        rel = call_with_backoff(ad.related_keywords, seed, show_detail=True, max_rows=1000)
        filtered = apply_filters(rel, min_volume, max_len, [t.strip() for t in ban_tokens.split(",") if t.strip()])
        ranked = rank_keywords(filtered, mobile_weight=1.2)
        annotate_intent(ranked)
        if not ranked:
            st.warning("Ï°∞Í±¥Ïóê ÎßûÎäî ÌÇ§ÏõåÎìúÍ∞Ä ÏóÜÏäµÎãàÎã§. ÌïÑÌÑ∞Î•º ÏôÑÌôîÌï¥ Î≥¥ÏÑ∏Ïöî.")
            st.stop()
        df = pd.DataFrame(ranked[:topn])

    # 2) DataLab ÏõîÍ∞Ñ Ìä∏Î†åÎìú
    with st.spinner("ÎÑ§Ïù¥Î≤Ñ Îç∞Ïù¥ÌÑ∞Îû©: Ìä∏Î†åÎìú(Ïõî Îã®ÏúÑ) Ï°∞Ìöå Ï§ë‚Ä¶"):
        end = dt.date.today()
        start = end - dt.timedelta(days=30 * months)
        kw_list = df["relKeyword"].head(5).tolist() or [seed]
        try:
            res = call_with_backoff(
                dl.trend, kw_list, start.strftime("%Y-%m-%d"), end.strftime("%Y-%m-%d"),
                time_unit="month", device=device
            )
        except Exception as e:
            res = {}
            st.info(f"DataLab Ìò∏Ï∂ú Ïã§Ìå®(Í≥ÑÏÜç ÏßÑÌñâ): {e}")

    rising = rising_from_datalab(res, topn=20) if res else pd.DataFrame()

    # 3) ÏàòÏùµ(ÌëúÏãúÏö©) Í≥ÑÏÇ∞
    money_df = df.copy()
    for c in ["monthlyAvePcClkCnt", "monthlyAveMobileClkCnt"]:
        if c not in money_df.columns:
            money_df[c] = 0
        money_df[c] = money_df[c].apply(_to_int)
    money_df["ÏõîÍ∞Ñ_ÌÅ¥Î¶≠_Ìï©Í≥Ñ"] = money_df["monthlyAvePcClkCnt"] + money_df["monthlyAveMobileClkCnt"]
    money_df["ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)"] = money_df["ÏõîÍ∞Ñ_ÌÅ¥Î¶≠_Ìï©Í≥Ñ"] * int(cpc_assume) + int(rpm_bonus)
    total_expected = int(money_df.get("ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)", pd.Series(dtype=int)).sum()) if not money_df.empty else 0

    # ÌÉ≠ Íµ¨ÏÑ±
    tabs = st.tabs([
        "ÏãúÏûëÌïòÍ∏∞",
        "ÌîåÎû´ÌèºÎ≥Ñ ÏàúÏúÑ",
        "Ï†úÎ™©/Î©îÌÉÄ Ï∂îÏ≤ú",
        "SERP ÌÖúÌîåÎ¶ø",
        "ÏãúÏ¶åÏÑ±",
        "Î°±ÌÖåÏùº Ï∂îÏ≤ú",
        "Íµ¨Í∏Ä ÏàúÏúÑ",
        "Ïù∏Í∏∞/Ïù∏Íµ¨ÌÜµÍ≥Ñ",
    ])

    # A) ÏãúÏûëÌïòÍ∏∞
    with tabs[0]:
        if st.session_state.get("_beginner"):
            st.markdown("### üë∂ Ï¥àÎ≥¥Ïûê Í∞ÄÏù¥Îìú")
            st.info("1) Ïî®Ïïó ÏûÖÎ†• ‚Üí 2) [Î∂ÑÏÑù Ïã§Ìñâ / Í∞±Ïã†] ‚Üí 3) [Î°±ÌÖåÏùº Ï∂îÏ≤ú]/[Ï†úÎ™©/Î©îÌÉÄ Ï∂îÏ≤ú] Ï∞∏Í≥† ‚Üí 4) Î∞úÌñâ Ï†Ñ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ ÌôïÏù∏ ‚Üí 5) [ÌîåÎû´ÌèºÎ≥Ñ/Íµ¨Í∏Ä ÏàúÏúÑ] ÌôïÏù∏")
            with st.expander("Î∞úÌñâ Ï†Ñ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏", expanded=True):
                c1, c2 = st.columns(2)
                with c1:
                    st.checkbox("ÌÇ§ÏõåÎìú 1Í∞ú = Í∏Ä 1Í∞ú", True, key="ck_kw1")
                    st.checkbox("ÏÑúÎ°† 3~5Î¨∏Ïû•, ÌïµÏã¨ ÏöîÏïΩ ÏÉÅÎã®", True, key="ck_intro")
                    st.checkbox("Ïù¥ÎØ∏ÏßÄ 3~5Ïû•(ALT Ìè¨Ìï®)", False, key="ck_img")
                with c2:
                    st.checkbox("Ï§ëÍ∞Ñ H2/H3Ïóê ÌÇ§ÏõåÎìú/Î≥ÄÌòï", True, key="ck_h2")
                    st.checkbox("ÏÉÅ/Ï§ë/Ìïò CTA Î∞∞Ïπò", True, key="ck_cta")
                    st.checkbox("ÎÇ¥Î∂ÄÎßÅÌÅ¨ 2~3Í∞ú", False, key="ck_internal")
            st.markdown("---")

        st.subheader("üìå Í∞úÏöî(ÌëúÏãúÏö©)")
        col1, col2 = st.columns(2)
        col1.metric("ÌëúÏãú ÌÇ§ÏõåÎìú Ïàò", fmt_int(len(money_df)))
        col2.metric("Ïõî ÏòàÏÉÅ Îß§Ï∂ú Ìï©Í≥Ñ(ÌëúÏãúÏö©)", fmt_won(total_expected))

        show = money_df.sort_values("ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)", ascending=False).head(30)[[
            "relKeyword", "intent", "monthlyPcQcCnt", "monthlyMobileQcCnt",
            "monthlyAvePcClkCnt", "monthlyAveMobileClkCnt", "ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)"
        ]].rename(columns={
            "relKeyword": "ÌÇ§ÏõåÎìú", "intent": "ÏùòÎèÑ", "monthlyPcQcCnt": "PCÍ≤ÄÏÉâÎüâ", "monthlyMobileQcCnt": "MOÍ≤ÄÏÉâÎüâ",
            "monthlyAvePcClkCnt": "PCÌÅ¥Î¶≠", "monthlyAveMobileClkCnt": "MOÌÅ¥Î¶≠"
        })
        for c in ["PCÍ≤ÄÏÉâÎüâ", "MOÍ≤ÄÏÉâÎüâ", "PCÌÅ¥Î¶≠", "MOÌÅ¥Î¶≠"]:
            show[c] = show[c].apply(_to_int).apply(fmt_int)
        show["ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)"] = show["ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)"].apply(fmt_won)
        st.dataframe(show, use_container_width=True)

        st.markdown("#### ‚úçÔ∏è Ïã§Ï†ú ÏûëÏÑ± Í∞ÄÏù¥Îìú(ÏÉÅÏúÑ 10)")
        plan_rows = []
        for _, r0 in money_df.sort_values("ÏòàÏÉÅ_Îß§Ï∂ú(Ïõê)", ascending=False).head(10).iterrows():
            it = r0.get("intent", "Ï†ïÎ≥¥")
            plan_rows.append({
                "ÌÇ§ÏõåÎìú": r0["relKeyword"],
                "ÏùòÎèÑ": it,
                "Í∂åÏû• Í∏Ä Ïú†Ìòï": beginner_article_type(it),
                "Ìã∞Ïä§ÌÜ†Î¶¨ Í¥ëÍ≥†": basic_ad_positions("Tistory"),
                "ÎÑ§Ïù¥Î≤Ñ Í¥ëÍ≥†": basic_ad_positions("Naver Blog"),
            })
        st.dataframe(pd.DataFrame(plan_rows), use_container_width=True)

        st.markdown("### üìà DataLab Í∏âÏÉÅÏäπ(Ïõî)")
        if isinstance(rising, pd.DataFrame) and not rising.empty:
            st.dataframe(rising, use_container_width=True)
        else:
            st.info("ÌëúÏãúÌï† Í∏âÏÉÅÏäπ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")

        st.markdown("---")
        if st.button("‚¨áÔ∏è ÏóëÏÖÄ ÎÇ¥Î≥¥ÎÇ¥Í∏∞(ÏàòÏùµ Ìè¨Ìï®)", key="btn_export_overview"):
            try:
                xlsx = export_keyword_report(seed, money_df.to_dict("records"), rising)
                st.success(f"Ï†ÄÏû• ÏôÑÎ£å: {xlsx}")
            except Exception as e:
                st.error(f"ÏóëÏÖÄ Ï†ÄÏû• Ïã§Ìå®: {e}")

        st.markdown("### ü§ù ÌòëÏ∞¨ Ï†úÏïàÏÑú ÎßåÎì§Í∏∞")
        c1, c2, c3 = st.columns([1, 1, 2])
        with c1:
            brand = st.text_input("Î∏åÎûúÎìú/ÏóÖÏ≤¥Î™Ö", value="Ïòà) Ïó¨ÌñâÏÇ¨ A")
        with c2:
            plat = st.selectbox("ÌîåÎû´Ìèº", ["Ìã∞Ïä§ÌÜ†Î¶¨", "ÎÑ§Ïù¥Î≤Ñ Î∏îÎ°úÍ∑∏"])
        with c3:
            pick_kw = st.selectbox("ÎåÄÏÉÅ ÌÇ§ÏõåÎìú", options=money_df["relKeyword"].head(10).tolist() or [seed])
        pitch = make_sponsor_pitch(brand, pick_kw, plat)
        st.text_area("Ï†úÏïàÏÑú Ï¥àÏïà", value=pitch, height=180)
        st.download_button("‚¨áÔ∏è ÌÖçÏä§Ìä∏ Ï†ÄÏû•", data=pitch.encode("utf-8"), file_name="sponsor_pitch.txt", key="dl_pitch")

        st.markdown("### üóìÔ∏è ÏΩòÌÖêÏ∏† Ï∫òÎ¶∞Îçî (4Ï£º Ï†úÏïà)")
        weeks = [
            ("1Ï£ºÏ∞®", "Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏/Ï§ÄÎπÑÎ¨ºÌòï 2Í∞ú + Q&A 1Í∞ú"),
            ("2Ï£ºÏ∞®", "Íµ¨Îß§Í∞ÄÏù¥Îìú 1Í∞ú + Î¶¨Î∑∞ 1Í∞ú + ÎπÑÍµê 1Í∞ú"),
            ("3Ï£ºÏ∞®", "ÎåÄÏïà/ÎπÑÍµê 2Í∞ú + ÎÖ∏ÌïòÏö∞ 1Í∞ú"),
            ("4Ï£ºÏ∞®", "ÏºÄÏù¥Ïä§ Ïä§ÌÑ∞Îîî 2Í∞ú + ÏöîÏïΩ ÌóàÎ∏å 1Í∞ú"),
        ]
        st.write("\n".join(f"- **{w}**: {plan}" for w, plan in weeks))

    # B) ÌîåÎû´ÌèºÎ≥Ñ ÏàúÏúÑ (ÎÑ§Ïù¥Î≤Ñ SERP)
    with tabs[1]:
        st.subheader("üîé ÌîåÎû´ÌèºÎ≥Ñ ÏàúÏúÑ (ÎÑ§Ïù¥Î≤Ñ SERP)")
        kw_rank = st.text_input("Î∂ÑÏÑù ÌÇ§ÏõåÎìú", value=seed, key="rank_kw")
        if st.button("ÏàúÏúÑ Ï°∞Ìöå", key="rank_check_main"):
            try:
                r = naver_platform_ranks(
                    kw_rank,
                    keys.get("NAVER_OPENAPI_CLIENT_ID", ""),
                    keys.get("NAVER_OPENAPI_CLIENT_SECRET", ""),
                    display=50
                )
                colA, colB = st.columns(2)
                nav_r = r["ranks"]["naver"]; tis_r = r["ranks"]["tistory"]
                colA.metric("ÎÑ§Ïù¥Î≤Ñ Î∏îÎ°úÍ∑∏ ÏµúÏ¥à ÎÖ∏Ï∂ú", f"{nav_r}ÏúÑ" if nav_r else "ÎØ∏ÎÖ∏Ï∂ú")
                colB.metric("Ìã∞Ïä§ÌÜ†Î¶¨ ÏµúÏ¥à ÎÖ∏Ï∂ú", f"{tis_r}ÏúÑ" if tis_r else "ÎØ∏ÎÖ∏Ï∂ú")

                st.markdown("**ÎÑ§Ïù¥Î≤Ñ Î∏îÎ°úÍ∑∏ ÏÉÅÏúÑ URL**")
                if r["naver_top"]:
                    st.write("\n".join(f"{x['rank']}ÏúÑ ¬∑ {x['url']}" for x in r["naver_top"]))
                else:
                    st.write("Í≤∞Í≥º ÏóÜÏùå")

                st.markdown("---")
                st.markdown("**Ìã∞Ïä§ÌÜ†Î¶¨ ÏÉÅÏúÑ URL**")
                if r["tistory_top"]:
                    st.write("\n".join(f"{x['rank']}ÏúÑ ¬∑ {x['url']}" for x in r["tistory_top"]))
                else:
                    st.write("Í≤∞Í≥º ÏóÜÏùå")
            except Exception as e:
                st.error(f"ÏàúÏúÑ Ï°∞Ìöå Ïã§Ìå®: {e}")

        st.markdown("---")
        st.subheader("üü† Ìã∞Ïä§ÌÜ†Î¶¨/Î∏îÎ°úÍ∑∏ Í≤ÄÏÉâ (Kakao Search)")
        kakao_key = st.text_input("Kakao REST API Key", value=keys.get("KAKAO_REST_API_KEY", ""), type="password")
        kw_kakao = st.text_input("Í≤ÄÏÉâ ÌÇ§ÏõåÎìú(Ïπ¥Ïπ¥Ïò§)", value=kw_rank)
        size_kakao = st.slider("Í∞ÄÏ†∏Ïò¨ Í∞úÏàò", 1, 50, 10, 1)
        if st.button("Ïπ¥Ïπ¥Ïò§ Î∏îÎ°úÍ∑∏ Í≤ÄÏÉâ", key="btn_kakao_search"):
            if not kakao_key:
                st.warning("Kakao REST API KeyÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.")
            else:
                docs = kakao_blog_search(kakao_key, kw_kakao, size=size_kakao, page=1, sort="recency")
                if not docs:
                    st.info("Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")
                else:
                    only_tistory = st.checkbox("Ìã∞Ïä§ÌÜ†Î¶¨Îßå Î≥¥Í∏∞", value=True)
                    rows = []
                    for d in docs:
                        url = d.get("url") or d.get("blogurl")
                        if only_tistory and (not url or "tistory.com" not in url):
                            continue
                        rows.append({
                            "title": d.get("title"),
                            "url": url,
                            "blogname": d.get("blogname"),
                            "datetime": d.get("datetime"),
                            "contents": d.get("contents"),
                        })
                    if rows:
                        st.dataframe(pd.DataFrame(rows), use_container_width=True)
                    else:
                        st.info("Ìã∞Ïä§ÌÜ†Î¶¨ Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§. Ï†ÑÏ≤¥ Î≥¥Í∏∞Î°ú ÌôïÏù∏Ìï¥Î≥¥ÏÑ∏Ïöî.")

        st.markdown("#### üß© ÏÉÅÏúÑ Í≤∞Í≥º Íµ¨Ï°∞ Î∂ÑÏÑù(Í∞ÑÎã®)")
        analyze_count = st.slider("Î∂ÑÏÑùÌï† ÏÉÅÏúÑ Í≤∞Í≥º Ïàò", 1, 20, 5, 1)
        if st.button("ÏÉÅÏúÑ Í≤∞Í≥º Íµ¨Ï°∞ Î∂ÑÏÑù", key="btn_kakao_analyze"):
            if not kakao_key:
                st.warning("Kakao REST API KeyÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§.")
            else:
                docs = kakao_blog_search(kakao_key, kw_kakao, size=analyze_count, page=1, sort="accuracy")
                if not docs:
                    st.info("Î∂ÑÏÑùÌï† Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")
                else:
                    met_rows = []
                    for d in docs:
                        url = d.get("url") or d.get("blogurl")
                        html = fetch_url_html(url)
                        m = analyze_html_structure(html)
                        met_rows.append({
                            "title": d.get("title"),
                            "url": url,
                            "words": m["words"],
                            "h2": m["h2"],
                            "h3": m["h3"],
                            "img": m["img"],
                            "table": m["table"],
                        })
                    dfm = pd.DataFrame(met_rows)
                    st.dataframe(dfm, use_container_width=True)
                    if not dfm.empty:
                        st.markdown("**ÌèâÍ∑†Í∞í(ÎåÄÎûµ)**")
                        avg = dfm[["words", "h2", "h3", "img", "table"]].mean(numeric_only=True).round(1)
                        st.write(avg.to_frame().T)
                    ideas = [f"- {d.get('title')}: {d.get('contents')[:80]}‚Ä¶" for d in docs]
                    st.markdown("**Îπ†Î•∏ ÏïÑÏù¥ÎîîÏñ¥**")
                    st.write("\n".join(ideas))

    # C) Ï†úÎ™©/Î©îÌÉÄ Ï∂îÏ≤ú
    with tabs[2]:
        st.subheader("üß≤ ÌÇ§ÏõåÎìúÎ≥Ñ Í≥†Ïú† Ï†úÎ™©/Î©îÌÉÄ")
        rows = []
        for i, r in money_df.head(50).reset_index(drop=True).iterrows():
            kw = r["relKeyword"]; it = r.get("intent", "Ï†ïÎ≥¥")
            pc = _to_int(r.get("monthlyPcQcCnt", 0)); mo = _to_int(r.get("monthlyMobileQcCnt", 0))
            pair = unique_title_meta_for_row(kw, it, pc, mo, rank=i)
            rows.append({"ÌÇ§ÏõåÎìú": kw, "ÏùòÎèÑ": it, "Ï†úÎ™©": pair["title"], "Î©îÌÉÄÎîîÏä§ÌÅ¨Î¶ΩÏÖò": pair["meta"]})
        st.dataframe(pd.DataFrame(rows), use_container_width=True)

    # D) SERP ÌÖúÌîåÎ¶ø (ÏÑ†ÌÉù)
    with tabs[3]:
        st.subheader("üß† ÏÉÅÏúÑ Íµ¨Ï°∞ Ï¥àÏïà (ÌîåÎû´ÌèºÎ≥Ñ)")
        st.caption("Í∞ÑÎã®Ìïú Íµ¨Ï°∞ Ï¥àÏïà/ÏïÑÏù¥ÎîîÏñ¥Îßå Ï†úÍ≥µÌï©ÎãàÎã§.")
        st.write("- ÏÑúÎ°†: ÏöîÏïΩ(ÌïµÏã¨/Î™©Ï∞®/Ï£ºÏùòÏÇ¨Ìï≠)")
        st.write("- Î≥∏Î¨∏(H2/H3): ÎπÑÍµêÌëú¬∑Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏¬∑ÏºÄÏù¥Ïä§¬∑FAQ")
        st.write("- Í≤∞Î°†: CTA(ÏÉÅ/Ï§ë/Ìïò), ÎÇ¥Î∂Ä/Ïô∏Î∂Ä ÎßÅÌÅ¨")

    # E) ÏãúÏ¶åÏÑ±
    with tabs[4]:
        st.subheader("üìÖ ÏãúÏ¶åÏÑ±/ÏßÄÏàò")
        try:
            sea_df = seasonality_table(res) if res else pd.DataFrame()
            idx = seasonal_index(sea_df) if not sea_df.empty else pd.DataFrame()
            if not idx.empty:
                view = idx.copy()
                for c in view.columns:
                    view[c] = view[c].apply(lambda x: f"{float(x)*100:.0f}%" if pd.notnull(x) else "-")
                st.markdown("**ÏõîÎ≥Ñ ÏÉÅÎåÄ ÏßÄÏàò(1.0 = Î≥¥ÌÜµ)**")
                st.dataframe(view, use_container_width=True)
            else:
                st.info("ÌëúÏãúÌï† ÏãúÏ¶åÏÑ± Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
        except Exception as e:
            st.warning(f"ÏãúÏ¶åÏÑ± Í≥ÑÏÇ∞ Ïò§Î•ò: {e}")

    # F) Î°±ÌÖåÏùº Ï∂îÏ≤ú
    with tabs[5]:
        st.subheader("üå± Î°±ÌÖåÏùº ÌÇ§ÏõåÎìú Ï∂îÏ≤ú")
        method = st.radio("Î∞©Ïãù", ["SearchAd API Í∏∞Î∞ò", "ÏûêÎèôÏôÑÏÑ± Î©ÄÌã∞-ÌîÑÎ°¨ÌîÑÌä∏(Ïã§ÏãúÍ∞Ñ)"], horizontal=True)

        def _export_df(df_out: pd.DataFrame, prefix: str) -> None:
            try:
                fname = f"{prefix}_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                df_out.to_excel(fname, index=False)
                st.success(f"Ï†ÄÏû• ÏôÑÎ£å: {fname}")
            except Exception as e:
                st.error(f"Ï†ÄÏû• Ïã§Ìå®: {e}")

        if method == "SearchAd API Í∏∞Î∞ò":
            min_clicks = st.number_input("ÏµúÏÜå ÏõîÌÅ¥Î¶≠(ÌïÑÌÑ∞)", 0, 100000, 20, 10)
            lt_df = suggest_longtails(df, min_clicks=min_clicks, max_items=300)
            if lt_df.empty:
                st.info("Ï°∞Í±¥ÏùÑ ÎßåÏ°±ÌïòÎäî Î°±ÌÖåÏùºÏù¥ ÏóÜÏäµÎãàÎã§. ÌïÑÌÑ∞Î•º ÎÇÆÏ∂∞Î≥¥ÏÑ∏Ïöî.")
            else:
                show_lt = lt_df.sort_values("ÏõîÌÅ¥Î¶≠", ascending=False).reset_index(drop=True)
                st.dataframe(show_lt, use_container_width=True)
                if st.button("‚¨áÔ∏è Î°±ÌÖåÏùº Ï∂îÏ≤ú ÏóëÏÖÄ Ï†ÄÏû•", key="btn_lt_export_api"):
                    _export_df(show_lt, "longtails_api")
        else:
            st.caption("‚Ä¢ Ïó¨Îü¨ ÌîÑÎ°¨ÌîÑÌä∏Î°ú ÎÑ§Ïù¥Î≤Ñ ÏûêÎèôÏôÑÏÑ±ÏùÑ Ï°∞ÌöåÌï¥, Ïã§Ï†ú Ï†úÏïàÎßå Î™®ÏïÑ Ï∂îÏ≤úÌï©ÎãàÎã§ (ÎçîÎØ∏ ÏóÜÏùå).")
            default_mods = "Ï∂îÏ≤ú, ÏàúÏúÑ, ÌõÑÍ∏∞, Í∞ÄÍ≤©, Ìï†Ïù∏, Ìå®ÌÇ§ÏßÄ, ÏùºÏ†ï, ÏΩîÏä§, Í∞ÄÏÑ±ÎπÑ, ÏàôÏÜå, ÎßõÏßë, ÏïÑÏù¥, Ïª§Ìîå, Î∂ÄÎ™®Îãò, 1Î∞ï2Ïùº, 2Î∞ï3Ïùº, ÎãπÏùº, 9Ïõî, 10Ïõî, Ï£ºÎßê"
            mods_text = st.text_input("ÌîÑÎ°¨ÌîÑÌä∏(ÏâºÌëú)", value=default_mods, help="Í∞Å Ìï≠Î™©ÏùÄ Ïî®Ïïó ÌÇ§ÏõåÎìúÏôÄ Ìï®Íªò ÏûêÎèôÏôÑÏÑ± Ï°∞ÌöåÏóê Ïì∞ÏûÖÎãàÎã§.")
            min_hits = st.slider("ÏµúÏÜå ÌûàÌä∏ Ïàò(Ïó¨Îü¨ ÌîÑÎ°¨ÌîÑÌä∏Ïóê Ï§ëÎ≥µ Îì±Ïû•)", 1, 5, 1, 1)
            max_items = st.slider("ÏµúÎåÄ Ï∂îÏ≤ú Í∞úÏàò", 10, 500, 200, 10)

            def multi_prompt_autocomplete(seed_kw: str, modifiers: List[str], limit: int = 200) -> pd.DataFrame:
                prompts = [seed_kw]
                for m in modifiers:
                    m = m.strip()
                    if not m:
                        continue
                    prompts.append(f"{seed_kw} {m}")
                hits: Dict[str, int] = {}
                sample_prompt: Dict[str, str] = {}
                for p in prompts:
                    sugs = fetch_naver_suggestions(p, "100") + fetch_naver_suggestions(p, "111")
                    for s in sugs:
                        hits[s] = hits.get(s, 0) + 1
                        sample_prompt.setdefault(s, p)
                rows = [
                    {"keyword": k, "hits": v, "prompt": sample_prompt.get(k, ""), "source": "naver_autocomplete"}
                    for k, v in hits.items()
                ]
                out = pd.DataFrame(rows).sort_values(["hits", "keyword"], ascending=[False, True]).head(limit).reset_index(drop=True)
                return out

            if st.button("Ïã§ÏãúÍ∞Ñ Ï∂îÏ≤ú Í∞ÄÏ†∏Ïò§Í∏∞", key="btn_mp_fetch"):
                modifiers = [t.strip() for t in mods_text.split(",") if t.strip()]
                ac_df = multi_prompt_autocomplete(seed, modifiers, limit=max_items)
                if ac_df.empty:
                    st.info("Ïã§ÏãúÍ∞Ñ Ï†úÏïàÏù¥ ÏóÜÏäµÎãàÎã§. ÌîÑÎ°¨ÌîÑÌä∏Î•º Î∞îÍæ∏Í±∞ÎÇò Î≥¥Ï°∞ Ïî®ÏïóÏùÑ ÏÇ¨Ïö©Ìï¥ Î≥¥ÏÑ∏Ïöî.")
                else:
                    vol_map: Dict[str, Dict[str, Any]] = {}
                    try:
                        rel2 = ad.related_keywords(seed, show_detail=True, max_rows=2000)
                        for r2 in rel2 or []:
                            k2 = str(r2.get("relKeyword", "")).strip()
                            if k2:
                                vol_map[k2] = r2
                    except Exception:
                        pass
                    ac_df["monthlyPcQcCnt"] = ac_df["keyword"].map(lambda k: _to_int((vol_map.get(k) or {}).get("monthlyPcQcCnt")))
                    ac_df["monthlyMobileQcCnt"] = ac_df["keyword"].map(lambda k: _to_int((vol_map.get(k) or {}).get("monthlyMobileQcCnt")))
                    ac_df["totalVolume"] = ac_df["monthlyPcQcCnt"] + ac_df["monthlyMobileQcCnt"]
                    show_ac = ac_df[ac_df["hits"] >= min_hits].sort_values(["hits", "totalVolume"], ascending=[False, False])
                    st.dataframe(show_ac, use_container_width=True)
                    if st.button("‚¨áÔ∏è Î°±ÌÖåÏùº Ï∂îÏ≤ú ÏóëÏÖÄ Ï†ÄÏû•", key="btn_lt_export_ac"):
                        _export_df(show_ac, "longtails_autocomplete")

    # G) Íµ¨Í∏Ä ÏàúÏúÑ (CSE)
    with tabs[6]:
        st.subheader("üîé Íµ¨Í∏Ä Í≤ÄÏÉâ ÏàúÏúÑ (CSE)")
        kw_g = st.text_input("Íµ¨Í∏Ä ÏàúÏúÑ ÌÇ§ÏõåÎìú", value=seed, key="g_kw")
        num_g = st.slider("Í≤ÄÏÇ¨ Í∞úÏàò(Íµ¨Í∏Ä)", 1, 10, 10, 1)
        g_api = keys.get("GOOGLE_API_KEY", "")
        g_cx = keys.get("GOOGLE_CSE_CX", "")
        if not g_api or not g_cx:
            st.info("GOOGLE_API_KEY / GOOGLE_CSE_CXÍ∞Ä ÏóÜÏúºÎ©¥ CSEÎ•º ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§.")
        else:
            if st.button("Íµ¨Í∏Ä ÏàúÏúÑ Ï°∞Ìöå", key="btn_google_rank"):
                try:
                    items = google_cse_search(g_api, g_cx, kw_g, num=num_g)
                    if not items:
                        st.info("Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.")
                    else:
                        st.markdown("**Top Í≤∞Í≥º**")
                        st.dataframe(pd.DataFrame(items), use_container_width=True)

                        col1, col2 = st.columns(2)

                except Exception as e:
                    st.error(f"Íµ¨Í∏Ä ÏàúÏúÑ Ï°∞Ìöå Ïã§Ìå®: {e}")

    # H) Ïù∏Í∏∞/Ïù∏Íµ¨ÌÜµÍ≥Ñ (Ïã§ÏãúÍ∞Ñ Ï†úÏïà + DataLab)
    with tabs[7]:
        st.subheader("üî• Ïù∏Í∏∞/Ïù∏Íµ¨ÌÜµÍ≥Ñ (Ïã§ÏãúÍ∞Ñ + DataLab)")
        sug = list(dict.fromkeys(
            fetch_naver_suggestions(seed, "100") + fetch_naver_suggestions(seed, "111")
        ))[:10]
        if sug:
            st.markdown("**ÎÑ§Ïù¥Î≤Ñ ÏûêÎèôÏôÑÏÑ±(Ïã§ÏãúÍ∞Ñ) Ï†úÏïà Top 10**")
            st.write("\n".join(f"- {s}" for s in sug))
        else:
            st.info("Ïã§ÏãúÍ∞Ñ Ï†úÏïàÏù¥ ÏóÜÏäµÎãàÎã§. Î≥¥Ï°∞ Ïî®ÏïóÏùÑ Ï∂îÍ∞ÄÌï¥ Î≥¥ÏÑ∏Ïöî.")

        try:
            end = dt.date.today()
            start = end - dt.timedelta(days=30)

            def _avg_ratio(gender: str) -> float:
                tr = dl.trend([seed], start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'), time_unit='date', gender=gender)
                rs = tr.get('results') or []
                if not rs or not rs[0].get('data'):
                    return 0.0
                vals = [x.get('ratio') or 0 for x in rs[0]['data']]
                return sum(vals)/len(vals) if vals else 0.0

            male = _avg_ratio('m')
            female = _avg_ratio('f')
            st.markdown("**ÏÑ±Î≥Ñ ÎπÑÏ§ë(ÏÉÅÎåÄÍ∞í)**")
            st.bar_chart(pd.DataFrame({"ratio": [male, female]}, index=["ÎÇ®ÏÑ±", "Ïó¨ÏÑ±"]))

            ages = ['10', '20', '30', '40', '50', '60']
            age_vals = []
            for a in ages:
                tr = dl.trend([seed], start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d'), time_unit='date', ages=[a])
                rs = tr.get('results') or []
                if not rs or not rs[0].get('data'):
                    age_vals.append(0.0)
                else:
                    vals = [x.get('ratio') or 0 for x in rs[0]['data']]
                    age_vals.append(sum(vals)/len(vals) if vals else 0.0)
            st.markdown("**Ïó∞Î†πÎåÄ ÎπÑÏ§ë(ÏÉÅÎåÄÍ∞í)**")
            st.bar_chart(pd.DataFrame({"ratio": age_vals}, index=[f"{a}ÎåÄ" for a in ages]))
        except Exception as e:
            st.info(f"Ïù∏Íµ¨ÌÜµÍ≥Ñ Ï°∞Ìöå Ï∞∏Í≥†: {e}")

else:
    st.info("ÏôºÏ™ΩÏóêÏÑú ÏòµÏÖòÏùÑ ÏÑ§Ï†ïÌïòÍ≥† **Î∂ÑÏÑù Ïã§Ìñâ / Í∞±Ïã†**ÏùÑ ÎàåÎü¨Ï£ºÏÑ∏Ïöî.")




